{
  "llm": {
    "provider": "openai",
    "model": "gpt-4",
    "api_base": null,
    "temperature": 0.1,
    "max_tokens": 4000,
    "timeout": 60
  },
  "graph": {
    "max_nodes": 10000,
    "max_edges": 50000,
    "cache_enabled": true,
    "cache_ttl": 3600
  },
  "server": {
    "host": "localhost",
    "port": 8000,
    "log_level": "INFO",
    "max_concurrent_tasks": 10,
    "task_timeout": 300
  }
}
