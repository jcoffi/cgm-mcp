{
  "llm": {
    "provider": "ollama",
    "model": "deepseek-coder:6.7b",
    "api_base": "http://localhost:11434",
    "temperature": 0.1,
    "max_tokens": 4000,
    "timeout": 120
  },
  "graph": {
    "max_nodes": 5000,
    "max_edges": 25000,
    "cache_enabled": true,
    "cache_ttl": 3600
  },
  "server": {
    "host": "localhost",
    "port": 8000,
    "log_level": "INFO",
    "max_concurrent_tasks": 3,
    "task_timeout": 300
  }
}
